\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{natbib, bbm}
\usepackage{url} % not crucial - just used below for the URL

\usepackage{amsthm}
\usepackage{lipsum}

\usepackage{xparse}
\usepackage{mathtools}
\usepackage[table,dvipsnames]{xcolor}

\usepackage{ifthen}
\usepackage{pstricks}
\usepackage[normalem]{ulem}

\usepackage{booktabs}
\usepackage{multirow}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\kmax}{k_{\text{max}}}
\newcommand{\lambdagrid}{\lambda^{\text{grid}}}


\RequirePackage[OT1]{fontenc}
\RequirePackage{amsthm,amsmath, bbm, xspace, graphics, graphicx}
%\RequirePackage{breqn}
%\RequirePackage[colorlinks,citecolor=blue,urlcolor=blue]{hyperref}

\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{1}
% \newcommand{\blind}{0}

\addtolength{\oddsidemargin}{-.75in}%
\addtolength{\evensidemargin}{-.75in}%
\addtolength{\textwidth}{1.5in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%


\begin{document}

%\bibliographystyle{natbib}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if1\blind
{
  \title{\bf Tuning parameter selection for a penalized estimator of species richness}
  \author{Alex Paynter and Amy D Willis\\ \\
  Department of Biostatistics, University of Washington,\\
  Health Sciences Building, Box 357232,\\
  1705 NE Pacific St., Seattle, WA 98195 \\ \\
  adwillis@uw.edu}

  \maketitle
} \fi

\if0\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Tuning parameter selection for a penalized estimator of species richness}
\end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
Our goal is to estimate the true number of classes in a population, called the species richness.  We consider the case where multiple frequency count tables have been collected from a homogeneous population, and investigate a penalized maximum likelihood estimator under a negative binomial model.  Because high probabilities of unobserved classes increase the variance of species richness estimates, our method penalizes the probability of a class being unobserved. Tuning the penalization parameter is challenging because the true species richness is never known, and so we propose and validate four novel methods for tuning the penalization parameter.  We illustrate and contrast the performance of the proposed methods by estimating the strain-level microbial diversity of Lake Champlain over 3 consecutive years, and global human host-associated species-level microbial richness.
\end{abstract}

\noindent%
{\it Keywords: diversity, regularization, maximum likelihood, ecology,  microbiome}
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!


% % List of authors, with corresponding author marked by asterisk
% \author{ALEX PAYNTER, AMY D WILLIS$^\ast$\\[4pt]
% % Author addresses
% \textit{Department of Biostatistics,
% University of Washington,
% Health Sciences Building, Box 357232,
% 1705 NE Pacific St., Seattle, WA 98195}
% % \\[2pt]
% % % E-mail address for correspondence
% % {payntera@uw.edu, adwillis@uw.edu}
% }
%
% % Running headers of paper:
% \markboth%
% % First field is the short list of authors
% {A. Paynter and A.D. Willis}
% % Second field is the short title of the paper
% {Tuning parameter selection for species richness}
%
% \maketitle
%
% % Add a footnote for the corresponding author if one has been
% % identified in the author list
% \footnotetext{adwillis@uw.edu}


\section{Introduction}
\label{sec:introduction}

The \textit{species problem} concerns estimating $C$, the number of classes that are present in a population.
$n$ individuals from the population can be sampled to find which classes they belong to, but since the  number of individuals in the sample is less than the total population size (which may be infinite), only $c$ classes are observed ($c \leq C$). The problem is named for its origins in biological ecosystems, where $C$ is \textit{species richness}, or the total number of species.  However, methods developed for the species problem can be applied to applications far removed from biology.  For example, \citet{efron_1976} estimated the number of words Shakespeare truly knew by modeling the frequencies of words in his published work, and  \citet{fegatelli_2018} estimated the number of cars covered by an insurer based on accident data where $c$ cars had at least one accident.

In ecology, species richness is a quantitative measurement of ecosystem diversity.  We focus on the specific application of estimating microbial diversity, that is, the number of strains of bacteria present in a population (e.g., a lake microenvironment or in an individual's oral cavity).
Microbial diversity is often linked with ecosystem health, such as in the vaginal microbiome (where high diversity is associated with infection \citep{Oakley:2008uo}) and in the gut microbiome (where high diversity is associated with healthy metabolism \citep{Morgan:2012bm,Minot:2019hc}).
Microbial abundance data typically contain many species observed infrequently (\textit{rare species}) and some which are observed a large number of times (\textit{abundant species}).  In data with both many rare and many abundant species, richness estimation methods often have high variance \citep{wang_2005,willis_2015}, motivating our regularized approach to estimation.

In this paper we consider the penalized maximum likelihood approach of \citet{wang_2005} and investigate the open problem of selecting the penalization parameter. Because the true species richness $C$ is never observed for any sample, common approaches to tuning parameter selection (e.g., cross-validation) cannot be employed. We propose using biological replicates to aid tuning. %, and so we extend the proposal of \citet{wang_2005} to the analysis of independent but homogeneous ecosystems.
We find that replicate data is advantageous for tuning the required penalization parameter and provide a comparison of the performance of 4 proposed methods for tuning parameter selection.

This paper is organized as follows: We review species richness estimation in Section \ref{sec:literature_review}.  In Section \ref{sec:fixed_lambda} we describe our extension to biological replicates, and in Section \ref{sec:efficacy_sims} we establish the utility of penalization via simulations. In Section \ref{sec:tuning_proposals} we propose several novel methods for tuning the penalization parameter, and in Section \ref{sec:tuning_simulations}
we evaluate our proposals. In Section \ref{sec:data_analysis} we apply our methods to estimate microbial diversity in Lake Champlain, and Section \ref{sec:discussion} closes with a discussion of our results and suggested directions for future work. Software implementing the methods is available in the \url{R} package \url{rre} (\textit{regularized richness estimation}), available at \url{github.com/statdivlab/rre}, and code to reproduce the simulation results is available at \url{github.com/statdivlab/rre_sims}.


\section{Literature Review}

\label{sec:literature_review}

\subsection{Poisson mixture models}

The classical model for estimating species abundance is a Poisson mixture model.  Under this model the number of times we observe species $i$ is $X_i \sim \text{Poisson}(\Lambda)$ where $\Lambda$ is a random variable distributed according to some mixing distribution.
Many mixing distributions have been proposed, including by  \cite{bulmer_1974,ord_1986,norris_1998} (see \cite{bunge_1993} for a comprehensive review). While our proposal may be easily generalized to other mixing distributions, in this paper we consider the Gamma  distribution for $\Lambda$, first considered by \citet{greenwood_yule} and \citet{fisher_1943}.
Note that we only observe $X_i | X_i > 0$, and therefore we are interested in estimating the parameters of a Poisson mixture model using \textit{zero-truncated} Poisson-mixed data.

Let $f_k = \#\{i: X_i = k\}$ be the number of classes observed $k$ times, called the \textit{frequency counts}.  Then the set $\{f_k\}_{k \geq 1}$ is a \textit{frequency count table}, a common way to represent species abundance data. Because $C = f_0 + f_1 + f_2 + \dots = f_0 + c$, the species problem can be framed as predicting $f_0$ given $f_1, f_2, \ldots$ to obtain a species richness estimate $\hat{C} = \hat{f}_0 + c$.

Let $\Lambda \sim \text{Gamma}(\alpha, \delta)$ with distribution function $f(\lambda) = \delta^\alpha \Gamma (\alpha)^{-1} \lambda^{\alpha - 1} e^{-\delta \lambda}$, and write $\eta = (\alpha, \delta)$.
% Then the distribution of $X_i$ under a gamma-Poisson model can written as a negative-binomial distribution,
% \begin{align}
% p_{\eta}(x) = \frac{\Gamma (x + \alpha)}{\Gamma (\alpha) x!} \left(\frac{\delta}{1+\delta} \right)^\alpha \left( \frac{1}{1+ \delta} \right)^x.
% \end{align}
% Note that we are interested in estimating the parameters of a negative binomial
% a zero-truncated negative binomial
%
There exist both frequentist \citep{fisher_1943,chao_2002} and Bayesian \citep{efron_1976,barger_2010} approaches to parameter estimation under this model. We will focus on frequentist maximum likelihood (penalized and unpenalized) in this paper.

\subsection{Estimation and computation}

The most straightforward maximum likelihood approach is to simultaneously maximize $C$ and $\eta$ using the full likelihood, which is known as the \textit{direct} approach.  A complication is that we have continuous parameters $\eta$ as well as one discrete parameter $C$, and so derivative-based optimization methods are not appropriate.  This issue has been studied by \citet{lindsay_1987}, who provide a discrete analog to the score function for this model.  %However, they point out that the asymptotics required use $C \to \infty$, which may not be appropriate for all problems.
Two other approaches to likelihood maximization are the \textit{conditional} and \textit{profile} approaches.  The conditional approach \citep{sanathanan_1977} involves writing the likelihood as the product
\begin{align}
 L(C, \eta) &= L_b(C, \eta)L_c(\eta) \label{eq:likelihood}
\end{align}
where
 \begin{align}
 L_b(C, \eta) &= \frac{C!}{(C-c)! \ c!} \left[1 - p_{\eta}(0) \right]^c \left[ p_{\eta}(0) \right]^{C-c}  %& \text{(``Binomial'' component)}
  \label{eq:binomial_likelihood}\\
 L_c(\eta) &= \frac{c!}{\displaystyle  \prod_{k \geq 1} f_k!} \prod_{k \geq 1} \left[ \frac{p_{\eta}(k)}{1-p_{\eta}(0)} \right]^{f_k}. \label{eq:conditional_likelihood} % & \text{(Multinomial component/``conditional'')}
\end{align}
We see that the likelihood is the product of a binomial probability mass function $c \sim$ Binomial $\left(C, 1- p_{\eta}(0)\right)$, and a multinomial probability mass function $(f_1, f_2, \ldots)|c \sim$  Multinomial $\left(c,  \frac{(p_{\eta}(1), p_{\eta}(2), \ldots)}{1-p_{\eta}(0)}\right)$.
This decomposition is convenient because $L_c$ is a function of $\eta$ alone.
% $L_b$ shows the probability of observing $c$ species follows a binomial distribution, i.e. $c \sim \text{Binomial}\left(C, 1- p_{\eta}(0)\right)$.  Letting $\kmax$ be the largest $k$ such that $f_k > 0$, $L_c$ shows that observing the frequency counts given by $f_1, f_2, \dots , f_{\kmax}$ follows a multinomial distribution given $c$.  The multinomial cell probabilities are proportional to $p_{\eta}(k)$.
\citet{sanathanan_1977}'s conditional approach to optimization involves first maximizing  $L_c(\eta)$ to obtain a conditional abundance estimate $\widehat{\eta}_c$, then maximizing $L_b(C, \widehat{\eta}_c)$ over $C$.
The conditional estimate of $C$ is then
\begin{equation}
\widehat{C}_c = \Biggl\lfloor \frac{c}{1-p_{\widehat{\eta}_c}(0)} \Biggr\rfloor \label{eq:conditional_c}
\end{equation}
where $\lfloor a \rfloor$ is the largest integer less than or equal to $a$.  In the \textit{profile} likelihood approach the expression in Equation \eqref{eq:conditional_c} is substituted into the full likelihood, which gives us a function of $\eta$ alone (see \citet{wang_2005}).  The conditional and profile approaches have been shown to be asymptotically equivalent to the direct approach.

% \citet{sanathanan_1977} uses this decomposition to propose the conditional approach to likelihood maximization, which is done in two steps (see \citet{chao_2002} for a detailed presentation).  First we maximize $L_c(\eta)$ to obtain a conditional abundance estimate $\widehat{\eta}_c$.  Then $L_b(C, \widehat{\eta}_c)$ is maximized over $C$.  With $\eta$ fixed there is a closed form expression for this second step,
% \begin{equation}
% \widehat{C}_c = \Biggl\lfloor \frac{c}{1-p_{\widehat{\eta}_c}(0)} \Biggr\rfloor %\label{eq:conditional_c}
% \end{equation}
% where $\lfloor a \rfloor$ is the largest integer less than or equal to $a$.  In the \textit{profile} likelihood approach the expression in Equation \eqref{eq:conditional_c} is substituted into the full likelihood, which gives us a function of $\eta$ alone (see \citet{wang_2005}).  The conditional and profile approaches have been shown to be asymptotically equivalent to the direct approach.

\subsection{Challenges with Poisson mixture models}


A perennial issue in the species problem, especially for microbial datasets, is the instability of species richness estimators \citep{Rocchetti:2011tv,willis_2015}.
% To illustrate, consider that a first-order approximation gives $$Var(\hat{C}_c | c) \approx \frac{c^2}{(1-\hat{p}(0))^4}Var(\hat{p}(0))$$ TODO check this
% Therefore,
% , especially maximum likelihood estimators.  The estimates often have unacceptably high variance and can become dramatically inflated.
%
%\sout{\textcolor{blue}{Since $Pr(X = 0) = \left( \frac{\delta}{1 + \delta}\right)^\alpha$, if there are many low abundance species then $\alpha$ will be near 0. Many high abundance species, as we see in microbial data, tends to cause $\delta$ to be near 0 as well.  The tendency of both abundance parameters to be near their boundary is one way to explain why this instability issue has plagued the species problem over a variety of approaches, and is especially prominent in microbial data.}}
%% One way of improving stability is to abandon the Poisson mixture paradigm entirely.  Though we will focus on the gamma-Poisson model in this paper, we would be remiss if we did not briefly mention other popular alternatives.  Coverage-based estimators, which use the proportion of species observed $k$ times rather than the actual counts were originally proposed by \citet{good_1953} and remain popular.  Capture-recapture methods (see \citet{chao_1987}) have a deep literature in animal abundance studies but are not as applicable in microbial data where the sampling  destroys the organism.  See \citet{bunge_1993} for a comprehensive review and \citet{bunge_2014} for an updated review of species richness methods which are outside the scope of this paper.
A proposal which encourages stability of estimates under Poisson-mixture models is due to \citet{wang_2005}.  Their proposal is to add a penalty term to the log-likelihood that penalizes the probability of observing a species zero times. They consider the
penalized log-likelihood
\begin{equation}
\ell_\lambda(C, \eta) = \ell(C,\eta) - \lambda \log p_{\eta}(0)
\label{eq:wang_lindsay}
\end{equation}
where $\ell(C,\eta) = \log L(C, \eta)$ is the log-likelihood and $\lambda > 0$ is a penalization parameter.
Let $\hat{C}_\lambda = \arg \max_{C} \ell_\lambda(C, \eta)$.
Then, for $\lambda \geq \lambda',$ $\hat{C}_\lambda \leq \hat{C}_{\lambda'}$ \citep[Theorem 1]{wang_2005}. In particular, for $\lambda > 0,$ the penalized maximum likelihood solution $\hat{C}_\lambda$ is less than or equal to $\hat{C}_0$, the maximum likelihood estimate. Furthermore, for a large enough $\lambda$, $\hat{C}_\lambda = c$; that is, the penalized maximum likelihood estimate shrinks to the observed richness $c$.

We note that $\log p_{\eta}(0) < 0,$ and so the addition of the ``penalty'' term in fact increases the objective function \eqref{eq:wang_lindsay} over the (unpenalized) likelihood $\ell(C,\eta)$.
While technically smaller $p_{\eta}(0)$ adds a larger reward to the objective function (for a fixed $\lambda$), we refer to the term $ - \lambda \log p_{\eta}(0)$ as a penalty
to be consistent with the terminology of \citet{wang_2005}.
\citet{wang_2005} also consider two other penalty functions, which we do not discuss here except to note that our tuning parameter selection methods would equally apply to these other penalty functions.

\citet{wang_2005} show that a trade-off exists: greater values of $\lambda$ correspond to a more stable estimator, but at the potential cost of negative bias.
The choice of penalization parameter implies a preference for lower variance or lower bias, adding subjectivity to the estimation procedure.
\citet{wang_2005} note that a limitation of their proposal is that ``one must select a penalty function and a tuning parameter, and it is nigh impossible to make convincing statements about why one choice should be uniformly superior to another.''
Furthermore, we expect different data sets to require different $\lambda$ values for optimal mean squared error.
% Our primary interest in studying the analysis of replicate frequency count tables is to leverage the replicates to tune the penalization parameter in Equation \eqref{eq:wang_lindsay}.
The goal of this paper is to propose and investigate data-adaptive methods to select $\lambda$.


\section{Extension to Biological Replicates}
\label{sec:fixed_lambda}

We focus on the gamma-Poisson model and penalized log-likelihood of the form \eqref{eq:wang_lindsay}, and consider the case where we observe $r$ independent frequency count tables from the population under study.
% with penalization as proposed by \citet{wang_2005}.  In this section we extend the penalized likelihood for a single frequency count table to the case where multiple frequency count tables have been collected.
We will assume that these $r$ frequency count tables are biological replicates drawn independently from the same population, i.e. they have a common structure specified by the parameters $C$ and $\eta$.  A set of $r$ frequency count tables from the same population will be called a \textit{sample}, and a single frequency count table will be referred to as a \textit{replicate}.  Let the number of species observed $k$ times in replicate $j$ be $f_{kj}$, $j \in \{1, \dots , r\}$.  Let $c_j$ be the observed richness in replicate $j$.

% Microbial data is often available as labeled abundance information $\{ X_{ij} \}$, the number of times species $i$ was observed in replicate $j$.  In this paper we study data represented in frequency counts $\{f_{kj}\}$ and it is worth pointing out that we lose some information in this representation.  For instance, in sample of frequency count tables it cannot be determined whether species $i$ was observed in two different replicates.  By using a mixed Poisson model we assume a common abundance structure between the species in order to estimate $C$.  While there may be other methods which leverage the additional information in an abundance table representation, the frequency counts are a minimal sufficient statistic for mixed Poisson models.

In Section \ref{sec:tuning_proposals} we will require an objective function defined in terms of a subset of indices of the frequency count tables, so we define it that way now.  Let $J \subseteq \{1, \dots, r\}$.  $J$ indicates the data being used in the evaluation of the objective function, with $J = \{1, \dots r\}$ meaning we use all replicates.  Let $\ell \left(C, \eta; \{f_{kj}\}_{k \geq 1} \right)$ be the unpenalized log-likelihood for replicate $j$.
Using the fact that the draws are independent, our objective function for a fixed $\lambda \geq 0$ is the sum of the log-likelihoods for each individual replicate.
We define the \textit{penalized log-likelihood} for multiple samples as
\begin{align}
\mathcal{O}_{\lambda}(C, \eta; J) :=& \sum_{j \in J} \ell \left(C, \eta; \{f_{kj}\}_{k \geq 1} \right) - \lambda\log p_{\eta}(0) \\
 =& \sum_{j \in J} \biggl[ \log C! - \log (C-c)! + (C-c) \log p_\eta(0)  \nonumber \\
 & \qquad  - \sum_{k \geq 1} \log{} f_{kj}! + \sum_{k \geq 1} f_{kj} \log p_\eta(k) \biggr] - \lambda \log p_\eta(0)    \label{eq:objective}
\end{align}
By fixing $\lambda = 0$ we obtain the unpenalized log-likelihood for the set $J$.  We define $\widehat{C}_{\lambda}$ to be the penalized maximum likelihood estimate of $C$ based on tuning parameter $\lambda$, that is,
\begin{equation}
\left(\widehat{C}_{\lambda},  \widehat{\eta}_{\lambda} \right) = \argmax_{C, \, \eta}  \mathcal{O}_{\lambda} \left(C, \eta ; \{1, \dots , r\} \right) \label{eq:ccc_hat_lambda}
\end{equation}
where $\widehat{\eta}_{\lambda}$ is a nuisance parameter.

To maximize the likelihood we will use the direct approach, rather than the profile and conditional approaches reviewed in Section \ref{sec:literature_review}.  While it may be faster to use the profile or conditional approach, the results are not always the same in finite samples.
Since our objective is to evaluate approaches to tuning, we place priority on the accuracy of optimization over speed of optimization.

To implement a direct optimization approach we search over candidate $C$ values in a grid.  A gradient-based search over $\eta$ values is used at each $C$ in the grid to find the maximum penalized likelihood  $(C, \eta)$.

\section{Evaluating penalized species richness estimates}
\label{sec:efficacy_sims}
% \subsection{Simulation setup}

Before evaluating potential tuning parameter selection methods, we first establish that penalization can improve richness estimation. While \citet{wang_2005} established that penalization can improve estimates when $r = 1$, this needs to be investigated when $r> 1$.

We use square root mean square error (RMSE) as the primary criterion for evaluating the performance of estimators.  Let $n_{\text{sim}}$ be the number of simulations completed for one choice of $(C, \eta, r)$, and $\widehat{C}_{\lambda \langle s \rangle}$ be the solution of Equation \eqref{eq:ccc_hat_lambda} obtained in simulation number $s$.  We define
\begin{equation}
 \text{RMSE}\left( \widehat{C}_{\lambda} \right) = \sqrt{ \frac{1}{n_{\text{sim}}} \sum_{s=1}^{n_{\text{sim}}} \left( \widehat{C}_{\lambda \langle s \rangle} - C\right)^2 }.
\end{equation}
In this simulation, if there exists some $\lambda > 0$ for which RMSE($\widehat{C}_{\lambda}$) is less than RMSE($\widehat{C}_0)$, we conclude that penalization is effective.

We simulated using $C = 1000$, and $r \in \{6, 10, 14\}$.  We found that $\eta = (\alpha, \delta) = (10^{-1}, 10^{-1})$  provided a good fit to the data of  \citet{walsh2014restricted}, and $\eta = (10^{-2}, 10^{-5})$ provided a good fit to the data of \citet{tromas_2017} (see Section \ref{sec:data_analysis}).
For completeness we also investigated nearby $\eta$ values: $\eta = \left( 10^{-1}, 10^{-3} \right)$ and $\eta = \left( 10^{-1}, 10^{-5}\right)$.
% To select $\eta$, we investigated the unregularized
%  two microbial datasets
% so choosing appropriate simulation values of $\eta$ is crucial in targeting our approach to microbial data.   We used two microbial datasets as motivating examples.  \citet{walsh2014restricted} provide a dataset from soil in a Swiss apple orchard and we found $\eta = (\alpha, \delta) = (10^{-1}, 10^{-1})$ produced a frequency count table with a similar structure to their data.  The second example from \citet{tromas_2017} is a sample of cyanobacteria from Lake Champlain, and we found $\eta = (10^{-2}, 10^{-5})$ mimicked the structure of their data well.  We note that is possible that the gamma-Poisson model is not the best fit for these examples, but our goal is only to choose $\eta$ in an appropriate range.  Two nearby $\eta$ values are included, $\eta = \left( 10^{-1}, 10^{-3} \right)$ and $\eta = \left( 10^{-1}, 10^{-5}\right)$.  These add variety to our simulations in this section and context for our simulations in Section \ref{sec:tuning_simulation_2}.  Under each combination of $\eta$ and $r$ 100 simulations were completed.
In Table \ref{tab:eta_intuition} we provide  summary measures for frequency count tables generated under each choice of $\eta$.  This characterizes the $\eta$ values by the proportion of unobserved, rare or abundant species we would expect to see. We return to a discussion of the different data structures in Section \ref{sec:tuning_simulations}.
For each combination of $\eta$ and $r$, we performed 100 simulations.
We investigated the grid $\lambda \in \{0, 5, \dots , 120\}$, and found that this grid was sufficiently expansive to ensure that the RMSE-minimising $\lambda$ was not on the boundary of the grid
(see Figures \ref{fig:fixed_lambda} and \ref{fig:fixed_lambda_2}).


% One final setting is necessary for these simulations: a set of $\lambda$ values to test over.  Our primary concern is to ensure the set covers the optimal value, i.e. $\lambda$ which produces the lowest RMSE$(\widehat{C}_{\lambda})$.  While we do not have a theoretical way to determine the ideal $\lambda$ set, we can use the known behavior of the penalty function to confirm that the set was sufficiently large after the simulation is complete.  As $\lambda$ increases, $\widehat{C}_{\lambda}$ decreases.  If $\widehat{C}_{\lambda_0}$ is  below the true $C$, then for $\lambda > \lambda_0$ $\widehat{C}_{\lambda}$ will be further from $C$, and the RMSE will increase.  Then we can be assured that the set is large enough if most or all simulations had a $\widehat{C}_{\lambda}$ below the truth for the largest $\lambda$ tested.
% This is clearly verifiable in the cases presented in Figures \ref{fig:fixed_lambda} and \ref{fig:fixed_lambda_2}. Simulating using $\lambda \in \{0, 5, \dots , 120\}$ was sufficient for all simulations in this section.


% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Thu May 23 22:11:47 2019
\begin{table}[t]
\caption{The expected proportion of unobserved ($k=0$), singleton ($k=1$), rare ($k=1,2,3$), and abundant  ($k \geq 10$) species for 4 choices of $\eta$.  We also give the expected frequency count of the most abundant species when $C = 1000$.
\label{tab:eta_intuition}}
\centering
\footnotesize
\begin{tabular}{rcccc}
  \hline
 $\eta = $ & ($10^{-1}$, $10^{-1}$) & ($10^{-2}$, $10^{-5}$) & ($10^{-1}$, $10^{-3}$) & ($10^{-1}$, $10^{-5}$) \\
  \hline
  Proportion unobserved ($p_{\eta}(0)$) & 0.787 & 0.891 & 0.501 & 0.316 \\
  Proportion singletons ($p_{\eta}(1)$) & 0.072 & 0.009 & 0.050 & 0.032 \\
  Proportion rare ($\sum_{k=1}^3 p_{\eta}(k)$) & 0.130 & 0.016 & 0.097 & 0.061 \\
  Proportion abundant ($\sum_{k=10}^{\infty} p_{\eta}(k)$) & 0.028 & 0.083 & 0.340 & 0.583 \\
Expected max abundance ($\mathbbm{E}\left[k_{\text{max}}\right]$) & $4.1 \times 10^{1}$ & $2.0 \times 10^{5}$ & $4.0 \times 10^{3}$ & $3.9 \times 10^{5}$ \\
   \hline
\end{tabular}
\normalsize
\end{table}

\begin{table}[t]
\caption{The penalized maximum likelihood estimate of $C$ has lower RMSE for all investigated choices of $\eta$ and $r$ under a zero-truncated Gamma-mixed Poisson model for species abundances based on 100 simulations for each choice of $\eta$ and $r$.
$\lambda_{\text{opt}}$ is the value of $\lambda$ which produced the lowest RMSE.
$\widehat{C}_0$ is the estimate of $C$ when $\lambda = 0$, and $\widehat{C}_{\lambda_{\text{opt}}}$ is the estimate of $C$ when $\lambda = \lambda_{\text{opt}}$.
\label{tab:fixed_lambda_results}}
\centering
\begin{tabular}{ccccc}
  \hline
$\eta = (\alpha, \delta)$ & $r$ & RMSE ($\widehat{C}_{0}$) & $\lambda_{opt}$ & RMSE ($\widehat{C}_{\lambda_{ \text{opt}}}$) \\
  \hline
$\left(10^{-1}, 10^{-1}\right)$ &   6 & 796.90 &  10 & 326.50 \\
$\left(10^{-1}, 10^{-1}\right)$ &  10 & 527.53 &  15 & 286.27 \\
  $\left(10^{-1}, 10^{-1}\right)$ &  14 & 337.31 &  10 & 235.51 \\
  $\left(10^{-2}, 10^{-5}\right)$ &   6 & 735.95 &  15 & 516.37 \\
  $\left(10^{-2}, 10^{-5}\right)$ &  10 & 700.21 &  20 & 456.04 \\
  $\left(10^{-2}, 10^{-5}\right)$ &  14 & 666.55 &  20 & 470.35 \\
  $\left(10^{-1}, 10^{-3}\right)$ &   6 & 200.09 &  20 & 156.29 \\
  $\left(10^{-1}, 10^{-3}\right)$ &  10 & 213.22 &  55 & 142.64 \\
  $\left(10^{-1}, 10^{-3}\right)$ &  14 & 243.42 &  55 & 148.26 \\
  $\left(10^{-1}, 10^{-5}\right)$ &   6 & 401.17 &  55 & 147.13 \\
  $\left(10^{-1}, 10^{-5}\right)$ &  10 & 283.91 &  25 & 137.04 \\
  $\left(10^{-1}, 10^{-5}\right)$ &  14 & 415.19 &  70 & 126.72 \\
   \hline
\end{tabular}
\end{table}

% \subsection{Simulation results} \label{sec:first_sim}

The results of the simulation are shown in Table \ref{tab:fixed_lambda_results}.  For every parameter choice a reduction in RMSE($\widehat{C}_{\lambda}$) was found for some $\lambda > 0$.  Depending on simulation parameters the reduction varied from 22\% to 70\% compared to RMSE($\widehat{C}_{0}$) for the best $\lambda$.  These results show that for a variety of $(\eta, r)$ choices, penalization improves species richness estimation.
We also see that the optimal $\lambda$ value varies considerably over $(\eta, r)$, ranging from 10 to 70.  This suggests that there is not a universally appropriate $\lambda$ choice. Therefore, tuning $\lambda$ to the sample appears desirable. We note that the optimal choice of $\lambda$ is not consistent either for fixed $r$ and variable $\eta$, nor for fixed $\eta$ and variable $r$.

To illustrate the bias-variance trade-off in this problem, we show the  effect on $\widehat{C}_{\lambda}$ of increasing $\lambda$ in Figure \ref{fig:fixed_lambda} (when $\eta = (10^{-1}, 10^{-1})$) and in Figure \ref{fig:fixed_lambda_2} (when $\eta = (10^{-2}, 10^{-5})$).
In both cases, for small values of $\lambda$ we observe lower variance in the estimates while incurring some negative bias, and the RMSE improves. However, as $\lambda$ continues to increase, the bias term becomes large and the RMSE increases.

\begin{figure}[p]
\caption{Estimates of $C$ and their root-MSE over $\lambda$ when $\eta = (10^{-1}, 10^{-1})$ and $C = 1000$. Results are based on 100 simulations per $\lambda$.
\label{fig:fixed_lambda}}
\centering\makebox[\textwidth]{\includegraphics[width=1\textwidth]{./images/fixed_lambda_eta1.pdf}}
\end{figure}


\begin{figure}[p]
\caption{Estimates of $C$ and their root-MSE over $\lambda$ when $\eta = (10^{-2}, 10^{-5})$ and $C = 1000$. Results are based on 100 simulations per $\lambda$.
\label{fig:fixed_lambda_2}}
\centering\makebox[\textwidth]{\includegraphics[width=1\textwidth]{./images/fixed_lambda_eta2.pdf}}
\end{figure}

\section{Methods for Tuning $\lambda$}
\label{sec:tuning_proposals}

We have established that penalization can improve richness estimates, but different abundance structures ($\eta$) require different values of $\lambda$ to minimize RMSE. We therefore develop methods to tune $\lambda$ based on a sample.  We propose several novel methods in this section.  Each is evaluated in Section \ref{sec:tuning_simulations}.

\setcounter{subsection}{-1}
\subsection{Method 0: No penalization}

We compare all proposed methods to the unpenalized MLE using $J = \{1, \dots r \}$:
%Recall that fixing $\lambda = 0$ gives us the unpenalized likelihood in Equation \eqref{eq:objective}, and so by denoting the $C$ estimate obtained using Method 0 as $\widehat{C}_{[0]}$, then
\begin{equation}
\left(\widehat{C}_{[0]},  \widehat{\eta}_{[0]} \right) = \argmax_{C, \, \eta}  \mathcal{O}_{0}\left(C, \eta ; \{1, \dots , r\} \right) \label{eq:c_hat_0}
\end{equation}
This method is fast and simple, making it an ideal baseline for comparison.

For all of the remaining methods (1-4) we generate estimates $\widehat{C}_\lambda$ over $\lambda \in \lambda^{\text{grid}}$, where $\lambdagrid$ is user-specified (e.g., $\lambdagrid = \{0, 5, 10, \dots 120\}$ in Section \ref{sec:efficacy_sims}).  %The methods differ in how they subset the data to create these estimates, and in the steps they take to arrive at a final estimate $\widehat{C}_{\text{[method]}}$.

%
%
\subsection{Method 1: Minimum subset variance}

Since large variance in $C$ is a major concern in species richness estimation, ideally an estimator will have low variance. If this is the case, there should be low variance in estimates from equally sized subsets of $J$.
% Method 1 is motivated by the belief that if we resample from the same population, an ideal $C$ estimator should have low variance.
For Method 1, we exploit the fact that we have replicate data by repeatedly partitioning the replicates into two subsets and calculating two estimates.  We then select the $\lambda$ which yields the lowest between-subset variance.  This partitioning is repeated $p$ times to average out the arbitrary choice of subsets.


Let $T_1(l)$ be the first subset of the $l^{\text{th}}$ partition and $T_2(l)$ be the second subset of the $l^{\text{th}}$ partition, for $l \in \{1, \dots , p\}$. That is, $T_i(l) \subseteq \{1, \dots , r\}$, $T_1(l) \cap T_2(l) = \emptyset$ and $T_1(l) \cup T_2(l) = \{1, \dots ,r\}$.
For each $\lambda \in \lambda^{\text{grid}}$, $l \in \{1, \dots, p\}$ let
\begin{align}
\left(\widehat{C}_{\lambda}^{ \ T_1(l)}, \widehat{\eta}_{\lambda}^{ \ T_1(l)} \right) &= \argmax_{C, \, \eta} \mathcal{O}_\lambda \left(C, \eta; T_1(l) \right) \\
\left(\widehat{C}_{\lambda}^{ \ T_2(l)}, \widehat{\eta}_{\lambda}^{ \ T_2(l)} \right) &= \argmax_{C, \, \eta} \mathcal{O}_\lambda \left(C, \eta; T_2(l) \right)
\end{align}
We now have a $\widehat{C}$ corresponding to each $\lambda \in \lambdagrid$ in each subset of each partition.  Our goal in Method 1 is to use these estimates to select the $\lambda$ value which gave us the lowest average variance over all partitions, denoted by $\widetilde{\lambda}_{[1]}$.  The overall estimate for Method 1, $\widehat{C}_{[1]}$, is a simple average of the estimates produced under $\widetilde{\lambda}_{[1]}$:
\begin{align}
\widetilde{\lambda}_{[1]} &= \argmin_{\lambda} \frac{1}{p} \sum_{l=1}^p \text{Var}\left[ \widehat{C}_{\lambda}^{ \ T_1(l)}, \widehat{C}_{\lambda}^{ \ T_2(l)} \right] \\
\widehat{C}_{[1]} &=  \frac{1}{p} \sum_{l=1}^p \left[ \frac{\widehat{C}_{\widetilde{\lambda}_{[1]}}^{ \ T_1(l)} + \widehat{C}_{\widetilde{\lambda}_{[1]}}^{ \ T_2(l)}}{2} \right]
\end{align}

In our simulations we chose an equal split of the indices for each partition: $|T_1(l)| = |T_2(l)|$.  The subsets of each partition are selected at random, and we sample with replacement.  We partition a total 10 times ($p = 10$).  For example, if $r = 4$ then $T_1(1) = \{1,4\}$ and $T_2(1) = \{2, 3\}$ would be valid subsets.  This approach to partitioning is also used in Methods 2 and 4.

\subsection{Method 2: Cross-validated likelihood}

% A frequently employed method that takes advantage of replicate data is cross-validation.  Cross-validation is commonly applied to evaluate the strength of a model in a dataset containing both features and outcomes \citep{statistical-machine-learning}. In this setting, the model is trained on one subset of the data and then evaluated using another.  However, in the species problem we never observe true outcomes: $C$ is only ever estimated, and never observed.  Methods 2 and 4 are motivated by the idea that subsets of the data should produce similar estimates,
 % desire to do something similar to cross-validation, but we have to find a function which takes the place of mean prediction error in the absence of any true $C$ observations.

In Method 2 we propose to repeatedly partition the data into subsets and evaluate the estimates based on the ``training'' subset using the likelihood based on the ``evaluation'' subset.
  % use one subset of the data to estimate $C$ and $\eta$.  Then we evaluate those estimates using the likelihood with the data from the other subset.  As before, w
We partition the data into two subsets $p$ times, calling them $T(l)$ for the training subset of the $l$-th partition, and $E(l)$ for the evaluation subset of the $l$-th partition. For each $\lambda \in \lambdagrid$, $l \in \{1, \dots , p\}$ let
\begin{equation}
\left(\widehat{C}_{\lambda}^{ \ T(l)}, \widehat{\eta}_{\lambda}^{ \ T(l)} \right) = \argmax_{C, \, \eta} \mathcal{O}_\lambda \left(C, \eta; T(l) \right), \label{eq:part_c_hats_method_2}
\end{equation}
that is, $\left(\widehat{C}_{\lambda}^{ \ T(l)}, \widehat{\eta}_{\lambda}^{ \ T(l)} \right)$ is the penalized maximum likelihood estimate evaluated on the \textit{training} subset.  The $\lambda$ value which maximizes the unpenalized likelihood calculated using the \textit{evaluation} subset is selected, and the average species richness estimate at $\widetilde{\lambda}_{[2]}$ is the estimated richness from Method 2:
\begin{align}
\widetilde{\lambda}_{[2]} &= \argmax_\lambda \sum_{l=1}^p \mathcal{O}_0\left( \widehat{C}_{\lambda}^{ \ T(l)}, \widehat{\eta}_{\lambda}^{ \ T(l)} ; \  E(l) \right) \label{eq:selected_lambda_2} \\
\widehat{C}_{[2]} &= \frac{1}{p} \sum_{l=1}^p \widehat{C}_{\widetilde{\lambda}_{[2]}}^{ \ T(l)}
\end{align}

 % In the evaluation step given in Equation \eqref{eq:selected_lambda_2} we use the unpenalized likelihood, as opposed to the penalized version.  The penalty term is in fact always positive, and has the potential dominate the likelihood if a very large $\lambda$ exists in $\lambdagrid$. For example, suppose we used the penalized likelihood and $10^7 \in \lambdagrid$.  Then no matter what data was passed in, Method 2 would select $\widetilde{\lambda} = 10^7$, and $\widehat{C}_{[2]}$ would shrink to the observed richness as a consequence.

%
%
%
\subsection{Method 3: Goodness of fit}

% We depart from our partitioning scheme to explore another desirable property of an estimator.
Method 3 uses goodness of fit of the fitted frequency counts to select an optimal tuning parameter.
% An ideal estimator would produce parameter estimates $\widehat{C}$, $\widehat{\eta}$ which fit well with the frequency counts in our sample.
% Consider a single frequency count table.
Given that $c \sim$ Binomial $\left(C, 1- p_{\eta}(0)\right)$ and $(f_1, f_2, \ldots)|c \sim$  Multinomial $\left(c,  \frac{(p_{\eta}(1), p_{\eta}(2), \ldots)}{1-p_{\eta}(0)}\right)$, we have that
\begin{equation}
 \mathbbm{E}\left[f_k\right] = \mathbbm{E}\left[\mathbbm{E}\left[f_k|c \right]\right] = \mathbbm{E}\left[ c \frac{p_{\eta}(k)}{1-p_{\eta}(0)} \right] = C\left(1-p_{\eta}(0) \right) \frac{p_{\eta}(k)}{1-p_{\eta}(0)} = Cp_{\eta}(k).
\end{equation}
Therefore, given estimates $\widehat{C}$ and $\widehat{\eta}$, we consider a plug-in estimate for the expected frequency counts: $\widehat{f_k} = \widehat{C}p_{\widehat{\eta}}(k)$.  The usual $\chi^2$ goodness of fit statistic is then
\begin{align}
\sum_{k=1}^{\infty} \frac{\left(f_k - \widehat{f}_k \right)^2 }{\widehat{f}_k} %&=\sum_{k=1}^{\infty} \frac{\left(f_k - \widehat{C}p_{\widehat{\eta}}(k) \right)^2 }{\widehat{C} p_{\widehat{\eta}(k)}}  \label{eq:chi_sq_compact} \\
&= \sum_{k=1}^{\kmax} \frac{\left(f_k - \widehat{C}p_{\widehat{\eta}}(k) \right)^2 }{\widehat{C} p_{\widehat{\eta}(k)}} \ + \ \widehat{C} \sum_{k = k_{max}+1}^{\infty} p_{\widehat{\eta}}(k)
\label{eq:chi_sq_expanded}
\end{align}
where $\kmax$ is the largest $k$ such that $f_k > 0$.
% Equation \eqref{eq:chi_sq_expanded} uses the fact that we have some $k_{max}$ in every frequency count table such that $f_k = 0$ for all $k > \kmax$.
% Therefore the statistic is a convergent sum, because the infinite sum is the tail of a distribution multiplied by a finite number $\widehat{C}$.
Equation \eqref{eq:chi_sq_expanded} is useful in software implementation as we can make use of precomputed tail probabilities $\sum_{k_{max}+1}^{\infty} p_{\widehat{\eta}}(k)$.
%Nonetheless we use Equation \eqref{eq:chi_sq_compact} below in extending to replicates for more concise notation.

In Method 3 we make use of this goodness of fit metric by first generating estimates using all replicates.  For each $\lambda \in \lambdagrid$ let
\begin{equation}
\left(\widehat{C}_{\lambda}, \widehat{\eta}_{\lambda} \right) = \argmax_{C, \, \eta} \mathcal{O}_\lambda \left(C, \eta; \left\{1, \dots, r \right\} \right). \label{eq:c_hat_lambdas_method_3}
\end{equation}
$\widetilde{\lambda}_{[3]}$ is the $\lambda$ value with the best-fitting estimates of $C$ and $\eta$:
\begin{align}
\widetilde{\lambda}_{[3]} &= \argmin_{\lambda} \sum_{j=1}^r \sum_{k=1}^{\infty} \frac{ \left( f_{kj} - \widehat{C}_{\lambda} p_{\widehat{\eta}_{\lambda}}(k) \right)^2}{\widehat{C}_{\lambda}p_{\widehat{\eta}_{\lambda}}(k)} \label{eq:selected_lambda_3}
\end{align}
and $\widehat{C}_{[3]}$ is the estimated value of $C$ at this choice of $\lambda$:
\begin{align}
\widehat{C}_{[3]} &= \widehat{C}_{\widetilde{\lambda}_{[3]}}
\end{align}
% In Equation \eqref{eq:selected_lambda_3} note the estimated counts $\left( \widehat{C}_{\lambda} p_{\widehat{\eta}_{\lambda}}(k) \right)$ are the same over all replicates ($j$).  This follows because we do not have independent $C, \eta$ estimates from each replicate, but a shared estimate for the sample.

An advantage of Method 3 that is not shared by Methods 1, 2 and 4 is that it can be used when $r=1$, that is, when no repeated measurements are available.

\subsection{Method 4: Cross-validated goodness of fit}

In Method 4 we return to the partitioning scheme of Method 2, but rather than using the likelihood in the evaluation step, we hypothesize that the goodness of fit metric may be a better choice.
We partition the data $p$ times, indexing the partitions by $l$. For each partition we have a training set $T(l)$ and a evaluation set $E(l)$.
For all $\lambda \in \lambdagrid$ and $l \in \{1, \dots , p \}$, we generate estimates exactly as in Method 2:
\begin{equation}
\left(\widehat{C}_{\lambda}^{ \ T(l)}, \widehat{\eta}_{\lambda}^{ \ T(l)} \right) = \argmax_{C, \, \eta} \mathcal{O}_\lambda \left(C, \eta; T(l) \right). \label{eq:c_hat_lambda_method_4}
\end{equation}
To select $\lambda$ we evaluate the goodness of fit metric using only the evaluation subset data, $j \in E(l)$.  The $\lambda$ which produces the best fitting estimates on the evaluation subset is $\widetilde{\lambda}_{[4]}$:
\begin{align}
\widetilde{\lambda}_{[4]} &= \argmin_{\lambda} \sum_{l = 1}^p \sum_{j \in E(l)} \sum_{k=1}^{\infty} \frac{ \left( f_{kj} - \widehat{C}_{\lambda}^{T(l)} p_{\widehat{\eta}_{\lambda}^{T(l)}}(k) \right)^2}{\widehat{C}_{\lambda}^{T(l)}p_{\widehat{\eta}_{\lambda}^{T(l)}}(k)}
\end{align}
and $\widehat{C}_{[4]}$ is the mean estimate of $C$ at  $\widetilde{\lambda}_{[4]}$, averaged all partitions $l$:
\begin{align}
\widehat{C}_{[4]} &= \frac{1}{p} \sum_{l=1}^p \widehat{C}_{\widetilde{\lambda}_{[4]}}^{T(l)}
\end{align}

Similar to Method 2, this method generates training set-based estimates $\widehat{C}^{T(l)}_{\lambda}$, however, it evaluates these estimates using goodness of fit rather than likelihood maximization.
Compared to Method 3, this method uses each replicate to either generate an estimate or evaluate the fit, while in Method 3 all replicates are used in both steps.

\section{Comparison of methods for selecting $\lambda$}
\label{sec:tuning_simulations}

We have proposed four tuning methods motivated by properties which would be desirable in an estimator of $C$.  In this chapter we compare the performance of each estimator.
We simulate zero-truncated gamma-mixed Poisson data using the same parameters used in Section \ref{sec:efficacy_sims}.
Based on the results of Section \ref{sec:efficacy_sims} we know that estimation can be improved through penalization, at least for the choices of $\eta$ that we propose to simulate from.  The purpose of this section is to determine if any method can reliably select a $\lambda$ that reduces RMSE compared to unpenalized maximum likelihood estimation.
In each simulation below, we select the largest value in $\lambdagrid$ by doubling the optimal value of $\lambda$ found in Table \ref{tab:fixed_lambda_results}.

% We present two simulations below, and in each it is important to select an appropriate $\lambdagrid$.
% % In particular our grid needs to be large enough to reveal the negative aspects of methods which over-penalize.  For instance, if $\lambdagrid = \{0, \dots , 50\}$ and the optimal value is $\lambda = 45$, a method which deterministically selects the maximum value in $\lambdagrid$ (an extreme over-penalizer) would perform well.  This would lead us to spuriously conclude this hypothetical over-penalizer is effective.
% In Section \ref{sec:efficacy_sims}  we established the approximate optimal values for each simulation setting (Table \ref{tab:fixed_lambda_results}).
% % One of the important foundations laid in Section \ref{sec:efficacy_sims} is that we now know approximately what the optimal values are for each simulation setting (Table \ref{tab:fixed_lambda_results}).
% We select a large enough grid by extending to at least double the optimal value in both simulations presented.

\subsection{Initial comparison of methods' performance}
\label{sec:tuning_simulation_1}

% \subsubsection{Setup}

In this simulation we let $C = 1000$, and simulate 100 times over all combinations of $\eta \in \{(10^{-1}, 10^{-1}), (10^{-2}, 10^{-5}) \}$, $r \in \{6, 10, 14\}$.  Recall these $\eta$ are the values chosen based on our motivating examples.  We know that the optimal $\lambda$ choice for these $r$ and $\eta$ are between 10 and 20, so we chose $\lambdagrid = \{0, 5, 10, \dots 60\}$ for this simulation.  Methods 0-4 are all evaluated over the same random draws for each parameter choice using the \texttt{R}
package \texttt{simulator} \citep{Bien:2016tg}.

% \subsubsection{Results}

In Table \ref{tab:tuning_sim_1} we show the RMSE over all simulations for each method and each combination of $\eta$ and $r$.  Over all parameter choices, Method 3 performs at least as well as Method 0, with a RMSE which was between 0 and 23\% lower.  Method 3 is the only method which performs at least as well as Method 0 for all parameter choices.

We note some differences between the performance of the methods for different $\eta.$ When $\eta = (10^{-2},10^{-5})$, Method 2 also outperforms Method 0 for $r \in \{6, 10, 14\}$, while Method 2 does not outperform Method 0 for any $r$ when $\eta = (10^{-1},10^{-1})$.  Method 4 outperforms Method 0 for $r \in \{6, 14\}$ when $\eta = (10^{-2},10^{-5})$, but never when $\eta = (10^{-1},10^{-1})$.
We conjecture that the differing performance across $\eta$ is due to the differing rare species structures implied by the different $\eta$'s. For example $\eta = (10^{-2},10^{-5})$ has more abundant species and larger expected maximum abundance $\mathbbm{E}(k_{\text{max}})$, but relatively few rare species (Table \ref{tab:eta_intuition}).

% Universally superior RMSE is the most desirable property for a method, but we can characterize the performance of the methods based on the simulation parameters as well.  For example, $\eta = (10^{-2},10^{-5})$ has more abundant species and larger expected maximum abundance $\mathbbm{E}(k_{\text{max}})$, but relatively few rare species (see Table \ref{tab:eta_intuition}).  The RMSE for Method 2 under this $\eta$ is 14-24\% smaller than Method 0, and for Method 4 the RMSE is slightly better for 2 of the 3 $r$ values.  Conversely, $\eta = (10^{-1}, 10^{-1})$ has more rare species and fewer abundant species and it is only Method 3 which has consistently improved performance.

% [Method 1 has better performance only for $r = 6$ on both $\eta$ choices.  In general, we would expect that any truly effective method would improve relative to Method 0 as $r$ increases, as this means more data was collected.  The fact that Method 1 loses its edge over Method 0 as we collect more data is a discouraging finding.  Method 3 shows the opposite trend, which is especially clear in Figure \ref{fig:tuning_sim_1} on $\eta = (10^{-2},10^{-5})$.  As we increase $r$ the simulations appear closer to the truth in Method 3, and Method 3 has the best RMSE for $r = 14$ under both $\eta$ values.]

\begin{table}[t]
\caption{RMSE$(\widehat{C})$ for Methods 0-4 based on a zero-truncated gamma-mixed Poisson data generating process. $C = 1000$ is constant for all simulations.  Under each $\eta, r$ combination, 100 simulations were run.  Methods with RMSE better than Method 0 have a \textcolor{blue!50}{blue} background, and the best method for each $\eta, r$ combination is \textbf{bolded}.
\label{tab:tuning_sim_1}}
\centering
\begin{tabular}{|l|c|c|c|c|c|c|}
\cline{2-7}
\multicolumn{1}{c}{} & \multicolumn{3}{|c|}{$\eta = (10^{-1},10^{-1})$} & \multicolumn{3}{|c|}{$\eta = (10^{-2},10^{-5})$} \\
\cline{2-7}
\multicolumn{1}{c}{} & \multicolumn{1}{|c|}{$r = 6$} & $r = 10$ & $r = 14$ & $r = 6$ & $r = 10$ & $r = 14$ \\
\hline
Method 0: MLE (no penalization)& 709 & \textbf{326} & \textbf{339} & 787 & 775 & 716 \\
\hline
Method 1: Minimum subset variance & \cellcolor{blue!25}{\textbf{689}} & 630 & 578 & \cellcolor{blue!25}{763} & 821 & 796 \\
\hline
Method 2: Cross-validated likelihood & 797 & 521 & 492 & \cellcolor{blue!25}{\textbf{602}} & \cellcolor{blue!25}{\textbf{658}} & \cellcolor{blue!25}{617} \\
\hline
Method 3: Goodness of fit & \cellcolor{blue!25}{707} & \cellcolor{blue!25}{\textbf{326}} & \cellcolor{blue!25}{\textbf{339}} & \cellcolor{blue!25}{781} & \cellcolor{blue!25}{663} & \cellcolor{blue!25}{\textbf{554}} \\
\hline
Method 4: Cross-validated g.o.f. & 812 & 571 & 533 & \cellcolor{blue!25}{738} & 787 & \cellcolor{blue!25}{679}  \\
\hline
\end{tabular}
\end{table}

In Figure \ref{fig:tuning_sim_1} we display the $C$ estimates for each method.  Recall that as we increase $\lambda$, $\widehat{C}_\lambda$ monotonically decreases.  Therefore we can discuss whether a method is on average over-penalizing (selecting $\widetilde{\lambda}$ which is larger than optimal) or under-penalizing (selecting $\widetilde{\lambda}$ which is smaller than optimal): if $\widehat{C} > C$, then the method has under-penalized while if $\widehat{C} < C$ the method has over-penalized.



\begin{figure}[t]
\caption{Simulation results for all proposed methods when $\eta = (10^{-1}, 10^{-1})$, and when $\eta = (10^{-2}, 10^{-5})$.
\label{fig:tuning_sim_1}}
\centering\makebox[\textwidth]{\includegraphics[width=\textwidth]{./images/method_sim_1.pdf}}
\end{figure}

We see from Figure \ref{fig:tuning_sim_1} that Method 1 over-penalizes for all parameter choices, as all of the estimates are far below the truth. We can understand this result given Figure \ref{fig:fixed_lambda}: for very high values of $\lambda$ the estimates are equal to $\max_j c_j$, and so have low variance. However, the observed richness is severely negatively biased for $C$. Given its large and consistent negative bias and high RMSE, we do not discuss  Method 1 further.

Method 2 has the opposite behavior: the estimates tend to be too high, especially when $\eta = (10^{-2}, 10^{-5})$. This is similarly the case for Method 0, though we see that Method 2 has slightly lower bias compared to Method 0.
Even for $\eta = (10^{-1}, 10^{-1})$, where the Method 0 bias is smaller, we see that Method 2 has poor performance (Table \ref{tab:tuning_sim_1}).  Recall that in each partition of Method 2 we use only half the data to generate the estimates $\widehat{C}^{T(l)}_{\lambda}$.  As a consequence Method 2 has slightly higher variance when compared with Method 0, as evidenced by the interquartile range in Figure \ref{fig:tuning_sim_1} for $\eta = (10^{-1}, 10^{-1})$.  In conclusion, Method 2 does not appear to be effectively
tuning $\lambda$, and sample splitting to generate estimates may be leading to high variance.

Methods 3 and 4, which are both based on goodness of fit criteria, display different patterns depending on the $\eta$ and $r$ values of the simulation.
Method 4 outperforms Method 0 when $\eta = (10^{-2}, 10^{-5})$ (Table \ref{tab:tuning_sim_1}), but under $\eta = (10^{-1}, 10^{-1})$ the RMSE for Method 4 is 15-75\% greater than for Method 0. In comparison, Method 3 is at least as good as Method 0 with respect to RMSE for all parameter combinations tested. In addition,  Method 3 is simpler and faster than Method 4.  We conclude that Method 3 is the most promising method based on this simulation.  We propose to conduct a secondary simulation to further investigate Method 3, testing whether it remains superior to Method 0 over a wider range of $\eta$ values.

\subsection{Performance over wider range of parameter values}
\label{sec:tuning_simulation_2}

% \subsubsection{Setup}

In this simulation we will fix $C = 1000$, $r \in \{6, 10, 14\}$ and perform 100 simulations for two additional choices of $\eta$.  We let $\eta \in \{ (10^{-1}, 10^{-3}), (10^{-1}, 10^{-5}) \}$ and only consider Methods 0 and 3, based on the results of the previous section.  To account for the fact that a larger $\lambda$ was optimal for these $\eta$ values (see Table \ref{tab:fixed_lambda_results}) we use $\lambdagrid = \{0,10,20, \dots 140 \}$.

\begin{table}[t]
\caption{RMSE for Methods 0 and 3.  Simulation parameters are grouped by $\eta$ and $r$, with $C = 1000$ fixed throughout.  For each $\eta$ and $r$ combination, 100 simulations were run.  If Method 3 has better performance than Method 0 is has a \textcolor{blue!50}{blue} background and it is \textbf{bolded}.
\label{tab:tuning_sim_2}}
\centering
\begin{tabular}{|l|c|c|c|c|c|c|}
\cline{2-7}
\multicolumn{1}{c}{} & \multicolumn{3}{|c|}{$\eta = (10^{-1},10^{-3})$} & \multicolumn{3}{|c|}{$\eta = (10^{-1},10^{-5})$} \\
\cline{2-7}
\multicolumn{1}{c}{} & \multicolumn{1}{|c|}{$r = 6$} & $r = 10$ & $r = 14$ & $r = 6$ & $r = 10$ & $r = 14$ \\
\hline
Method 0: MLE (no penalization) & \textbf{228} & \textbf{236} & \textbf{188} & \textbf{163} & 426 & 681 \\
\hline
Method 3: Goodness of fit & 260 & 274 & 256 & 183 & \cellcolor{blue!25}{\textbf{175}} & \cellcolor{blue!25}{\textbf{191}} \\
\hline
\end{tabular}
\end{table}

% \subsubsection{Results}

In Table \ref{tab:tuning_sim_2} we display the RMSE for both methods and each combination of $r$ and $\eta$.  Method 3 has slightly worse performance on all $r$ values for $\eta = (10^{-1}, 10^{-3})$, with a RMSE which was 14-36\% greater than Method 0. $\eta = (10^{-1}, 10^{-3})$ generates more rare species than $\eta = (10^{-1}, 10^{-5})$
(assessed as $\sum_{k=0}^3 p_\eta(k)$), so the comparatively poor performance of Method 3 is consistent with the results our previous simulation: in Section \ref{sec:tuning_simulation_1}, we found that Method 3 improved estimation in data with abundant species ($\eta = (10^{-2}, 10^{-5})$),
but the improvements over Method 0 were less pronounced in datasets that had more rare species ($\eta = (10^{-1}, 10^{-1})$).

We also note that Method 3 has 12\% higher RMSE on $r=6, \eta = (10^{-1}, 10^{-5})$, but as $r$ increases Method 3 improves relative to Method 0.  This finding is also consistent with our previous simulation where Method 3 tends to perform better as more data is introduced.

In Figure \ref{fig:tuning_sim_2} we display boxplots of the $C$ estimates over all simulations.  For $\eta = (10^{-1}, 10^{-5})$ we note that $\widehat{C}_{[0]}$ is very large for a few simulations.  We recall from Table \ref{tab:eta_intuition} that this $\eta$ choice has the highest proportion of abundant species.  This is an example of a simulation structure which will cause the instability problem in maximum likelihood estimation discussed in Section \ref{sec:literature_review}.
Method 3 outperforms Method 0 on this $\eta$ by selecting lower estimates.

\begin{figure}[t]
\caption{Simulation results for Methods 0 and 3 when $\eta = (10^{-1}, 10^{-3})$, and when and $\eta = (10^{-1}, 10^{-5})$.
\label{fig:tuning_sim_2}}
\centering\makebox[\textwidth]{\includegraphics[width=\textwidth]{./images/method_sim_2.pdf}}
\end{figure}

While Table \ref{tab:tuning_sim_2} suggests that Method 3 has larger RMSE than Method 0, Figure \ref{fig:tuning_sim_2} suggests that when  $\eta = (10^{-1}, 10^{-3})$, the estimates produced by the methods are very similar. The advantage of Method 3 over Method 0 when $\eta = (10^{-1}, 10^{-5})$ for increasing $r$ is also clearer, since we see that Method 3 reduces the incidence of outlying estimates.

As a result of these simulations, we conclude that no method (including Method 0) is best for all simulation settings, but Method 3 has advantages in many settings. Method 3 had improved performance compared to Method 0 when there are highly abundant species present in the data, in which case Method 0 is highly unstable.  When there are many rare species Method 3 is better than Methods 1, 2 and 4, but is not necessarily better than Method 0.  Method 3 also improved relative to Method 0 with greater $r$.  Methods 2 and 4 had lower RMSE than Method 0 when highly abundant species exist, but have inferior performance compared to Method 3 on data dominated by rare species. Method 1 resulted in a strong negative bias in all simulations, and we do not recommend its use.

\section{Data Analysis}
\label{sec:data_analysis}

\subsection{Estimating microbial richness in Lake Champlain}

To illustrate the performance of our methods on ecological data, we estimate strain-level microbial diversity in Lake Champlain, a large eutrophic lake in Canada.  We analyze data from \citet{tromas_2017}, considering samples from the littoral zone in the summer season of the same year as replicates. This gives us 8 replicates from 2009, 6 replicates from 2010 and 6 replicates from 2011. Given our results from \ref{sec:tuning_simulations}, we focus on Methods 0 and 3.

Method 3 produces lower estimates of $C$ than Method 0, as expected.
The 2009 and 2010 estimates were approximately $3.5$ times lower for Method 3, while the 2011 estimate was approximately $1.5$ times lower for Method 3. We see that the estimates of $\delta$ are comparable across the two methods, but that the estimates of $\alpha$ differ, and may be higher or lower depending on the dataset.

% The richness estimates from each method are displayed in Figure \ref{fig:data_analysis} and Table \ref{tab:data_analysis_compact}.  Method 0 produces the highest estimate for 2009 ($\widehat{C}_{[0]} = 73,404$) and 2010 ($\widehat{C}_{[0]}$ = 47,631) and it was second highest to Method 2 in 2011
% ($\widehat{C}_{[0]} = 57,686$ and $\widehat{C}_{[2]} = 118,547$).  Method 1 consistently estimated $C$ to be at or near the observed richness, $\widehat{C}_{[1]} = 584$ in 2009,  $572$ in 2010 and $718$ in 2011.  Methods 3 and 4, which both use goodness of fit, were between these two extremes.  These results mirror what we observed in simulations, where Methods 0 and 2 generated the highest estimates and Method 1 was the lowest (see Figure \ref{fig:tuning_sim_1}).
%
% These estimates are up to 165 times the observed richness, suggesting that a majority of the species were unobserved in each sample.  The relatively large estimates suggest that these data may be poorly fit by the negative binomial model.


\begin{table}[t]
\caption{Diversity estimates from the Lake Champlain data analysis from 2009 ($r = 8$), 2010 ($r = 6$) and 2011 ($r = 6$) using our proposed methods.
\label{tab:data_analysis_compact}}
\centering
\tiny
\begin{tabular}{lllllllllllll}
  \toprule
      & \multicolumn{4}{c}{2009} & \multicolumn{4}{c}{2010} & \multicolumn{4}{c}{2011} \\ \cmidrule(lr){2-5}\cmidrule(lr){6-9}\cmidrule(lr){10-13}
Method & $\widehat{C}$ & $\widetilde{\lambda}$ & $\widehat{\alpha}$ & $\widehat{\delta}$ & $\widehat{C}$ & $\widetilde{\lambda}$ & $\widehat{\alpha}$ & $\widehat{\delta}$ & $\widehat{C}$ & $\widetilde{\lambda}$ & $\widehat{\alpha}$ & $\widehat{\delta}$ \\
  \midrule
{[0]} Unpenalized MLE & 73,404 & \textemdash & 0.00088 & 0.00180 & 47,631 & \textemdash & 0.00185 & 0.00253 & 57,686 & \textemdash & 0.00161 & 0.00140 \\
  % {[1]} Minimum Variance & 584 & 700 & 0.28863 & 0.00326 & 572 & 500 & 0.62668 & 0.00724 & 718 & 500 & 0.40112 & 0.00355 \\
  % {[2]} CV Likelihood & 25,930 & 220 & 0.00516 & 0.00142 & 24,799 & 0 & 0.00379 & 0.00270 & 118,547 & 0 & 0.00122 & 0.00193 \\
  {[3]} Goodness of fit & 20,160 & 550 & 0.00323 & 0.00174 & 13,156 & 225 & 0.00685 & 0.00257 & 40,040 & 230 & 0.00231 & 0.00137 \\
  % {[4]} CV G.O.F. & 36,893 & 85 & 0.00246 & 0.00251 & 47,098 & 0 & 0.00208 & 0.00277 & 36,395 & 5 & 0.00358 & 0.00178 \\
   \bottomrule
\end{tabular}
\end{table}

% \begin{figure}[t]
% \caption{Estimates of strain-level microbial diversity in Lake Champlain in the summers of 2009 ($r = 8$), 2010 ($r = 6$) and 2011 ($r = 6$) using our proposed methods.
% \label{fig:data_analysis}}
% \centering\makebox[\textwidth]{\includegraphics[width=\textwidth]{./images/data_analysis_expanded.pdf}}
% \end{figure}


% The richness estimates from each method are displayed in Figure \ref{fig:data_analysis}.  We see that Methods 0 and 3 produce identical estimates for all samples, and these estimates are larger than estimates for Methods 1, 2 and 4. We note that Methods 1, 2 and 4 use partitioning, but the trend of lower estimates for partition-based estimates was not observed in simulations (see Figure \ref{fig:tuning_sim_1}).



% Our estimates from each method are all at least 10 times as high as the observed richness, indicating that a significant fraction of species were unobserved. Based on our previous results, estimation error is lowest for Methods 0 and 3 when there are many rare species. We therefore estimate $\widehat{C}^{2009} = 11200$, $\widehat{C}^{2010} = 11440$ and $\widehat{C}^{2011} = 14014$.
% , and in some cases they reach the maximum value in our grid search for $C$ (which is 20 times the observed richness).

% In Figure \ref{fig:data_analysis} we display the same results visually.  The methods which use partitioning (Methods 1, 2 and 4) consistently produce lower estimates than those which do not (Methods 0 and 3).  This trend was not found in simulations, where the highest estimates came from Method 2 and the lowest from Method 1.  This may suggest that partitioning methods have an advantage on real data which could have greater heterogeneity between replicates than data generated from simple parametric distributions.

% \begin{figure}[t]
% \caption{Estimates of strain-level microbial diversity in Lake Champlain in the summers of 2009 ($r = 8$), 2010 ($r = 6$) and 2011 ($r = 6$) based on our proposed methods.
% %$\widehat{C}_{[\text{method}]}$ is the $C$ estimate obtained using the methods defined in Section \ref{sec:tuning_proposals}, shown for each sample.  The number of replicates in each sample is given by $r$.
% %
% % A visual display of the results from Table \ref{tab:data_analysis}, $\widehat{C}$ estimates from each method.
% \label{fig:data_analysis}}
% \centering\makebox[\textwidth]{\includegraphics[width=\textwidth]{./images/data_analysis.pdf}}
% \end{figure}
%
% \noindent \alex{Next: Modify the discussion to harmonious with what you've written here.}


\subsection{Estimating global human host-associated microbial richness}

We also applied our method to estimate the species-level diversity of human host associated microbes.
\cite{pasolli2019extensive} assembled $c=4,930$ species-level genome bins (SGBs) using publicly available shotgun metagenomic data, but we expect that many SGBs were not observed due to undersampling and challenges in genome assembly. The frequency counts of each SGB are available at \citet[Table S4]{pasolli2019extensive}.

In this dataset $r=1$, and so it is not possible to sample split replicate frequency count tables. Therefore, only Methods 0 and Method 3 can be applied. We found that $\widehat{C}_{[0]} = 420,056$ with $(\hat{\alpha}, \hat{\delta}) = (0.00234, 0.00641).$ In contrast, $\widehat{C}_{[3]} = 163,587$ with $\tilde{\lambda}_{[3]} = 905$ and  $(\hat{\alpha}, \hat{\delta}) = (0.00605, 0.00635).$
% $(\hat{\alpha}, \hat{\delta}) = (0.006045614, 0.006352191).$
% With $\lambdagrid = \{0, 0.25, \ldots, 1100\}$ we found that Method 3 selected $\lambda = 913.5$. However, $\widehat{C}_{[3]} = 98600$
% We found that $\widehat{C}_{[3]} = 163587$ with $\tilde{\lambda}_{[3]} = 905$ and $(\hat{\alpha}, \hat{\delta}) = (0.006045614, 0.006352191).$ % GOF = 11196564679
We therefore find Method 3 to produce an estimate approximately $2.5$ times lower than the estimate produced by Method 0. Similar to our analysis of the \cite{tromas_2017} dataset, we find comparable $\hat{\delta}$'s across the two methods but different $\hat{\alpha}$'s.

\section{Discussion}

\label{sec:discussion}

\subsection{Conclusions}

In this paper we outlined an extension of the penalized maximum likelihood procedure of \citet{wang_2005} for species richness estimation to data with biological replicates, and proposed several methods for tuning the penalization parameter.  We demonstrated that penalization can reduce estimation error when analyzing replicate data.
We found that tuning the penalization parameter is challenging, but that a tuning method based on goodness of fit (Method 3) has better performance than the unpenalized MLE in 8 of the 12 parameter combinations we analyzed. On two datasets we found that it reduces the magnitude of species richness estimates. Since species richness estimates can be unstable, we find the reduction in estimates appealing. While we cannot conclude that our proposed goodness of fit tuning parameter selection method provides more reliable estimates than unregularized estimation, the performance of the goodness of fit approach on simulated data is encouraging.

Our investigation highlights the challenges of selecting tuning parameters in the absence of a ground truth, since we never observe $C$. However, even in the absence of information with which to calibrate $\lambda$, we showed that
with a parametric model for species abundance data we can use goodness of fit in conjunction with maximum likelihood to select $\lambda$.
We conjecture that the goodness of fit method performs well because it employs a combination of likelihood and goodness of fit metrics calculated on the full dataset to select the tuning parameter, unlike methods that only rely on likelihood (e.g., Method 2) or split the data (e.g., Method 4).

% We have been careful to try to create methods which only depend on $\lambdagrid$ being large enough to contain the optimal value, with no change in results if it is too large.  This makes $\lambdagrid$ a more forgiving parameter than fixed $\lambda$ values, but we still need to make a choice to analyze data.  Faster computation times would aid in this problem because we could set a default grid which is generously large, thus alleviating concerns that our results are dependent on our choice.  Additionally, it may be possible to select $\lambdagrid$ for the methods adaptively.  For instance, we could expand the grid until the fixed estimates (e.g. $\widehat{C}_{\lambda}$ in Equation \eqref{eq:c_hat_lambdas_method_3}) have been suppressed to the observed richness.  Choosing $\lambdagrid$ remains a consideration when applying our methods.

% Method 3 was our top performer and it is the only tuning method we proposed which can be run without replicates ($r = 1$).  The ever-decreasing cost of high-throughput sequencing suggests biological replicates might be more available in the future.  However, there are currently more projects with a single frequency count table available.  Exploring the use of Method 3 for single frequency count tables is a worthwhile extension of our work for this reason.

\subsection{Limitations and future work}

The approach of \citet{wang_2005} is considerably more general than the
-Poisson model.  The gamma-Poisson model is common for modeling microbiome data \citep{deseq2,holmes2018modern}, and for this reason we focused on it in our investigation. However, our goodness of fit method is also amenable to other parametric models. We leave investigation of tuning parameter selection under different models to future work.

Our results from Section \ref{sec:fixed_lambda} hint at a possible positive correlation between $r$ and the optimal choice of $\lambda$. We investigated whether the optimal choice of $\lambda$ remained constant for penalties of the form $-h(r)\lambda \log p_{\eta}(0)$ (instead of $-\lambda \log p_{\eta}(0)$; see Equation \eqref{eq:objective}).
We tested $h(r) = r$ and $h(r) = \sqrt{r}$, but found that the trend in optimal $\lambda$ is not so simple. We leave further investigation into how the optimal $\lambda$ varies with $r$ to future work. Understanding of $h(r)$ would allow us to consider unequally sized evaluation and training partitions for Methods 2 and 4.

For our investigations, we intentionally chose a likelihood optimization algorithm which was stable and exhaustive. We also did not construct standard errors for our estimates, and the long computation times precluded the consideration of a bootstrapping approach. Refining the optimization algorithm would be a valuable extension, and a faster optimization algorithm would facilitate a resample-based variance estimation procedure.


\section{Code References}

An \texttt{R} package implementing our methods is available at \texttt{github.com/statdivlab/rre}. Code to reproduce our figures and simulations can be found at \texttt{github.com/statdivlab/rre\_sims}. We are also grateful to the \cite{r_project} and authors of the packages \texttt{tidyverse} \citep{tidyverse}, \texttt{magrittr} \citep{magrittr}, \texttt{breakaway} \citep{breakawaypkg}, \texttt{foreach} \citep{foreach}, \texttt{Rcpp} \citep{Rcpp} and \texttt{data.table} \citep{datatable}, which were used for constructing the figures and running the analyses in this paper.

\section*{Acknowledgments}
The authors of this manuscript are grateful to Jim Hughes for many helpful suggestions that improved content and exposition. This work was supported in part by the National Institute of General Medical Sciences (NIGMS) of the NIH under Grant R35 GM133420.

{\it Conflicts of Interest}: None to declare.

\bibliographystyle{biorefs}
% \bibliographystyle{natbib}
% \bibliographystyle{Chicago}
\bibliography{refs,amys-papers-library}


\end{document}
